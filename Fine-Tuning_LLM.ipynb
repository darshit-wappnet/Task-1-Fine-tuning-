{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers[sentencepiece] datasets sacrebleu rouge_score py7zr -q\n!pip install peft","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T04:23:48.207042Z","iopub.execute_input":"2025-06-02T04:23:48.207807Z","iopub.status.idle":"2025-06-02T04:24:59.466195Z","shell.execute_reply.started":"2025-06-02T04:23:48.207780Z","shell.execute_reply":"2025-06-02T04:24:59.465228Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.3/141.3 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.9/412.9 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.9.0.13 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.4.0.6 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.10.19 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.4.40 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.9.5 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.9.41 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mRequirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (25.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (7.0.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.51.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\nRequirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.5.2)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\nRequirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.31.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (2025.3.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft)\n  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft)\n  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft)\n  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft)\n  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.0->peft)\n  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft)\n  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.0->peft)\n  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->peft) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->peft) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->peft) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->peft) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2025.4.26)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->peft) (2024.2.0)\nUsing cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\nUsing cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\nUsing cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\nUsing cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\nUsing cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\nDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\nimport torch\nfrom datasets import load_dataset,DatasetDict\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Trainer, TrainingArguments\nfrom peft import LoraConfig, get_peft_model, TaskType\nfrom transformeimport evaluate\nimport evaluate\n\n# torch.manual_seed(42)\n\n# dataset = load_dataset(\"SurAyush/News_Summary_Dataset\")\n# dataset = dataset.shuffle(seed=42)\n# dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T04:26:02.942047Z","iopub.execute_input":"2025-06-02T04:26:02.942445Z","iopub.status.idle":"2025-06-02T04:26:30.336526Z","shell.execute_reply.started":"2025-06-02T04:26:02.942414Z","shell.execute_reply":"2025-06-02T04:26:30.335679Z"}},"outputs":[{"name":"stderr","text":"2025-06-02 04:26:17.043439: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748838377.238141      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748838377.296273      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from datasets import load_dataset, concatenate_datasets, DatasetDict\n\ndataset = load_dataset(\"SurAyush/News_Summary_Dataset\")[\"train\"]\ndata_1 = load_dataset(\"gopalkalpande/bbc-news-summary\")[\"train\"]\n\ndata_1 = data_1.remove_columns([\"File_path\"])\ndata_1 = data_1.rename_columns({\"Articles\": \"article\", \"Summaries\": \"summary\"})\n\ncombined_dataset = concatenate_datasets([data_1, dataset])\n\nfinal_dataset = DatasetDict({\"train\": combined_dataset})\n\nprint(final_dataset)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T04:26:49.604782Z","iopub.execute_input":"2025-06-02T04:26:49.605469Z","iopub.status.idle":"2025-06-02T04:26:53.909795Z","shell.execute_reply.started":"2025-06-02T04:26:49.605445Z","shell.execute_reply":"2025-06-02T04:26:53.909221Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/1.22k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b191dd897b5b4c8db43b4d1047edc0f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"news_summaries.csv:   0%|          | 0.00/7.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11c7f61501164775a29e4bcab13404e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/2224 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbc3ea4fa48443a2995559e6c76161bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffdb0cc4f31c4b9e8dbac6928f691696"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"bbc-news-summary.csv:   0%|          | 0.00/7.32M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2f1f57eba2f49088ea78e6580f3f454"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/2224 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0d45300d89d4774b81957c421e9e322"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['article', 'summary'],\n        num_rows: 4448\n    })\n})\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"split_dataset =  final_dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\nprint(\"Dataset after split:\", split_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T04:26:56.986217Z","iopub.execute_input":"2025-06-02T04:26:56.986588Z","iopub.status.idle":"2025-06-02T04:26:56.999421Z","shell.execute_reply.started":"2025-06-02T04:26:56.986556Z","shell.execute_reply":"2025-06-02T04:26:56.998722Z"}},"outputs":[{"name":"stdout","text":"Dataset after split: DatasetDict({\n    train: Dataset({\n        features: ['article', 'summary'],\n        num_rows: 4003\n    })\n    test: Dataset({\n        features: ['article', 'summary'],\n        num_rows: 445\n    })\n})\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"model_name = \"t5-base\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T04:26:58.928273Z","iopub.execute_input":"2025-06-02T04:26:58.928551Z","iopub.status.idle":"2025-06-02T04:27:03.739405Z","shell.execute_reply.started":"2025-06-02T04:26:58.928531Z","shell.execute_reply":"2025-06-02T04:27:03.738458Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d66a65818d1140ea988ef03f765fceb1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"185207befb134c9598241f59bcf0a4fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce6551c3ca304c179370e6e7c2d42e93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2f1abc105dd424aac08834d72321d51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39ed32686f1949a287bfd2bd508009e5"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"def preprocess_function(examples):\n    inputs = [\"summarize: \" + doc for doc in examples[\"article\"]]\n    model_inputs = tokenizer(\n        inputs,\n        max_length=512,\n        truncation=True,\n        padding=\"max_length\",\n    )\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(\n            examples[\"summary\"],\n            max_length=256,\n            truncation=True,\n            padding=\"max_length\",\n        )\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T04:27:03.740767Z","iopub.execute_input":"2025-06-02T04:27:03.741022Z","iopub.status.idle":"2025-06-02T04:27:03.746337Z","shell.execute_reply.started":"2025-06-02T04:27:03.741004Z","shell.execute_reply":"2025-06-02T04:27:03.745461Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"tokenized_datasets = split_dataset.map(preprocess_function, batched=True)\ntokenized_datasets = tokenized_datasets.remove_columns([\"article\", \"summary\"])\nprint(\"Tokenized datasets:\", tokenized_datasets)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T04:27:11.651423Z","iopub.execute_input":"2025-06-02T04:27:11.652047Z","iopub.status.idle":"2025-06-02T04:27:17.982808Z","shell.execute_reply.started":"2025-06-02T04:27:11.652025Z","shell.execute_reply":"2025-06-02T04:27:17.982227Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4003 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed1755f93d2e46fd9a1e186d8d7981d8"}},"metadata":{}},{"name":"stdout","text":"Tokenized datasets: DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 4003\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 445\n    })\n})\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"train_dataset = tokenized_datasets[\"train\"].select(range(4000))\neval_dataset = tokenized_datasets[\"test\"].select(range(410)) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T04:27:17.983986Z","iopub.execute_input":"2025-06-02T04:27:17.984339Z","iopub.status.idle":"2025-06-02T04:27:17.992681Z","shell.execute_reply.started":"2025-06-02T04:27:17.984310Z","shell.execute_reply":"2025-06-02T04:27:17.991940Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"print(\"Train dataset:\", train_dataset) \nprint(\"Validation dataset:\", eval_dataset) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T04:27:20.052668Z","iopub.execute_input":"2025-06-02T04:27:20.053150Z","iopub.status.idle":"2025-06-02T04:27:20.057464Z","shell.execute_reply.started":"2025-06-02T04:27:20.053126Z","shell.execute_reply":"2025-06-02T04:27:20.056659Z"}},"outputs":[{"name":"stdout","text":"Train dataset: Dataset({\n    features: ['input_ids', 'attention_mask', 'labels'],\n    num_rows: 4000\n})\nValidation dataset: Dataset({\n    features: ['input_ids', 'attention_mask', 'labels'],\n    num_rows: 410\n})\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"lora_config = LoraConfig(\n    task_type=TaskType.SEQ_2_SEQ_LM,\n    r=8,  \n    lora_alpha=32,\n    lora_dropout=0.1,\n    target_modules=[\"q\", \"v\"],  \n)\n\n# Apply LoRA to the model\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters() ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T04:27:26.819988Z","iopub.execute_input":"2025-06-02T04:27:26.820307Z","iopub.status.idle":"2025-06-02T04:27:26.913614Z","shell.execute_reply.started":"2025-06-02T04:27:26.820288Z","shell.execute_reply":"2025-06-02T04:27:26.913048Z"}},"outputs":[{"name":"stdout","text":"trainable params: 884,736 || all params: 223,788,288 || trainable%: 0.3953\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/lora-t5-news-summarization\",eval_strategy=\"epoch\",learning_rate=1e-3,per_device_train_batch_size=5,per_device_eval_batch_size=5,\n    num_train_epochs=3,weight_decay=0.01,\n    save_strategy=\"epoch\",\n    save_total_limit=2,\n    load_best_model_at_end=True,fp16=True, \n    logging_dir=\"/kaggle/working/logs\",logging_steps=100,\n    report_to='none'\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T04:27:26.914265Z","iopub.execute_input":"2025-06-02T04:27:26.914494Z","iopub.status.idle":"2025-06-02T04:27:26.950141Z","shell.execute_reply.started":"2025-06-02T04:27:26.914474Z","shell.execute_reply":"2025-06-02T04:27:26.949615Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"rouge = evaluate.load(\"rouge\")\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    \n    # Replace -100 in the labels as we can't decode them\n    labels = [[(l if l != -100 else tokenizer.pad_token_id) for l in label] for label in labels]\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n    return {k: round(v, 4) for k, v in result.items()}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    compute_metrics=compute_metrics\n)\n\ntrainer.train()  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T04:27:26.951350Z","iopub.execute_input":"2025-06-02T04:27:26.951549Z","iopub.status.idle":"2025-06-02T04:50:15.473000Z","shell.execute_reply.started":"2025-06-02T04:27:26.951534Z","shell.execute_reply":"2025-06-02T04:50:15.472454Z"}},"outputs":[{"name":"stderr","text":"No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\nPassing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1200' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1200/1200 22:45, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.456200</td>\n      <td>0.395610</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.462100</td>\n      <td>0.373885</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.431800</td>\n      <td>0.367535</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1200, training_loss=0.5467392158508301, metrics={'train_runtime': 1367.5798, 'train_samples_per_second': 8.775, 'train_steps_per_second': 0.877, 'total_flos': 7340109594624000.0, 'train_loss': 0.5467392158508301, 'epoch': 3.0})"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"model.save_pretrained(\"/kaggle/working/lora-t5-news-final\")\ntokenizer.save_pretrained(\"/kaggle/working/lora-t5-news-final\") ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T04:53:07.305387Z","iopub.execute_input":"2025-06-02T04:53:07.306087Z","iopub.status.idle":"2025-06-02T04:53:07.526912Z","shell.execute_reply.started":"2025-06-02T04:53:07.306067Z","shell.execute_reply":"2025-06-02T04:53:07.526206Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/lora-t5-news-final/tokenizer_config.json',\n '/kaggle/working/lora-t5-news-final/special_tokens_map.json',\n '/kaggle/working/lora-t5-news-final/spiece.model',\n '/kaggle/working/lora-t5-news-final/added_tokens.json',\n '/kaggle/working/lora-t5-news-final/tokenizer.json')"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"metrics = trainer.evaluate()\nprint(\"Evaluation metrics:\", metrics)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T04:53:10.438033Z","iopub.execute_input":"2025-06-02T04:53:10.438599Z","iopub.status.idle":"2025-06-02T04:53:10.442699Z","shell.execute_reply.started":"2025-06-02T04:53:10.438575Z","shell.execute_reply":"2025-06-02T04:53:10.441893Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\nfrom peft import PeftModel, PeftConfig","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T04:53:15.803638Z","iopub.execute_input":"2025-06-02T04:53:15.803896Z","iopub.status.idle":"2025-06-02T04:53:15.807633Z","shell.execute_reply.started":"2025-06-02T04:53:15.803880Z","shell.execute_reply":"2025-06-02T04:53:15.806711Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"model_path = \"/kaggle/working/lora-t5-news-final\"\ntokenizer = AutoTokenizer.from_pretrained(model_path)\npeft_config = PeftConfig.from_pretrained(model_path)\nbase_model = AutoModelForSeq2SeqLM.from_pretrained(peft_config.base_model_name_or_path)\nmodel = PeftModel.from_pretrained(base_model, model_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T04:53:18.903714Z","iopub.execute_input":"2025-06-02T04:53:18.903987Z","iopub.status.idle":"2025-06-02T04:53:19.459100Z","shell.execute_reply.started":"2025-06-02T04:53:18.903969Z","shell.execute_reply":"2025-06-02T04:53:19.458514Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T04:53:24.606849Z","iopub.execute_input":"2025-06-02T04:53:24.607316Z","iopub.status.idle":"2025-06-02T04:53:24.951881Z","shell.execute_reply.started":"2025-06-02T04:53:24.607293Z","shell.execute_reply":"2025-06-02T04:53:24.951189Z"},"jupyter":{"outputs_hidden":true},"collapsed":true},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"PeftModelForSeq2SeqLM(\n  (base_model): LoraModel(\n    (model): T5ForConditionalGeneration(\n      (shared): Embedding(32128, 768)\n      (encoder): T5Stack(\n        (embed_tokens): Embedding(32128, 768)\n        (block): ModuleList(\n          (0): T5Block(\n            (layer): ModuleList(\n              (0): T5LayerSelfAttention(\n                (SelfAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=768, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=768, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (k): Linear(in_features=768, out_features=768, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=768, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=768, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (o): Linear(in_features=768, out_features=768, bias=False)\n                  (relative_attention_bias): Embedding(32, 12)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (1): T5LayerFF(\n                (DenseReluDense): T5DenseActDense(\n                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                  (act): ReLU()\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n          (1-11): 11 x T5Block(\n            (layer): ModuleList(\n              (0): T5LayerSelfAttention(\n                (SelfAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=768, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=768, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (k): Linear(in_features=768, out_features=768, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=768, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=768, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (o): Linear(in_features=768, out_features=768, bias=False)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (1): T5LayerFF(\n                (DenseReluDense): T5DenseActDense(\n                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                  (act): ReLU()\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n        )\n        (final_layer_norm): T5LayerNorm()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (decoder): T5Stack(\n        (embed_tokens): Embedding(32128, 768)\n        (block): ModuleList(\n          (0): T5Block(\n            (layer): ModuleList(\n              (0): T5LayerSelfAttention(\n                (SelfAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=768, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=768, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (k): Linear(in_features=768, out_features=768, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=768, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=768, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (o): Linear(in_features=768, out_features=768, bias=False)\n                  (relative_attention_bias): Embedding(32, 12)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (1): T5LayerCrossAttention(\n                (EncDecAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=768, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=768, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (k): Linear(in_features=768, out_features=768, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=768, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=768, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (o): Linear(in_features=768, out_features=768, bias=False)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (2): T5LayerFF(\n                (DenseReluDense): T5DenseActDense(\n                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                  (act): ReLU()\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n          (1-11): 11 x T5Block(\n            (layer): ModuleList(\n              (0): T5LayerSelfAttention(\n                (SelfAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=768, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=768, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (k): Linear(in_features=768, out_features=768, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=768, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=768, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (o): Linear(in_features=768, out_features=768, bias=False)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (1): T5LayerCrossAttention(\n                (EncDecAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=768, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=768, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (k): Linear(in_features=768, out_features=768, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=768, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=768, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (o): Linear(in_features=768, out_features=768, bias=False)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (2): T5LayerFF(\n                (DenseReluDense): T5DenseActDense(\n                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                  (act): ReLU()\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n        )\n        (final_layer_norm): T5LayerNorm()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"text = \"\"\"\nBJP Returns to Power in Delhi After 27 Years: Rekha Gupta Becomes Chief Minister\n\nIn a landmark political shift, the Bharatiya Janata Party (BJP) has reclaimed power in the Delhi Legislative Assembly after a 27-year hiatus. The 2025 elections, held on February 5, culminated in a decisive victory for the BJP, which secured 48 out of 70 seats, surpassing the majority threshold of 36 seats. This triumph ended the Aam Aadmi Party's (AAP) decade-long governance in the national capital. \nIndia TV News\n+1\nIndia Today\n+1\n\nElection Outcomes\nBJP: 48 seats\n\nAAP: 22 seats\n\nCongress: 0 seats\nIndia TV News\n+3\nIndia Today\n+3\nWikipedia\n+3\n@mathrubhumi\n+5\nThe Times of India\n+5\nWikipedia\n+5\nBusiness Standard\n\nThe BJP's vote share stood at 47.15%, marking a significant increase from the 38.51% it garnered in the 2020 elections. Conversely, AAP's vote share declined to 43.57% from its previous 53.57%. \nIndia TV News\n+1\nWikipedia\n+1\n\nLeadership Changes\nFollowing the BJP's victory, Rekha Gupta was appointed as the Chief Minister of Delhi. Gupta, who won from the Shalimar Bagh constituency, became the first woman to hold this position in the city. Her leadership marks a new chapter in Delhi's political landscape. \nWikipedia\n\nNotable Defeats\nThe election results were particularly significant for the AAP, as several of its prominent leaders faced defeats:\nIndia TV News\n\nArvind Kejriwal: The former Chief Minister lost the New Delhi seat to BJP's Parvesh Verma.\n\nManish Sisodia: The former Deputy Chief Minister was defeated in the Jangpura constituency by BJP's Tarvinder Singh Marwah.\n\nSaurabh Bharadwaj: The outgoing Health Minister lost the Greater Kailash seat to BJP's Shikha Roy.\nThe Times of India\n+1\nIndia TV News\n+1\nIndia Today\n+2\nIndia TV News\n+2\nBusiness Standard\n+2\n\nDespite these setbacks, some AAP leaders managed to retain their seats:\n\nAtishi: Won from the Kalkaji constituency.\n\nGopal Rai: Secured the Babarpur seat.\n\nImran Hussain: Retained the Ballimaran constituency.\nIndia Today\n\nReactions and Future Outlook\nPrime Minister Narendra Modi hailed the BJP's victory as a mandate for development and good governance. He expressed gratitude to the people of Delhi for their support and emphasized the party's commitment to fulfilling its promises. \nBusiness Standard\n+1\nWIONews\n+1\nWIONews\n\nThe AAP, on the other hand, acknowledged the electoral setback and pledged to introspect and rebuild. Party leaders emphasized their continued dedication to public service and vowed to play a constructive role in the opposition.\n\nAs the BJP assumes control of Delhi's administration, the focus is expected to shift towards implementing its development agenda, enhancing infrastructure, and addressing key issues such as pollution and public transportation. The political dynamics in the capital are poised for significant changes under the new leadership.\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T05:42:06.313874Z","iopub.execute_input":"2025-06-02T05:42:06.314492Z","iopub.status.idle":"2025-06-02T05:42:06.319350Z","shell.execute_reply.started":"2025-06-02T05:42:06.314469Z","shell.execute_reply":"2025-06-02T05:42:06.318455Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"inputs = tokenizer(\"summarize: \" + text, return_tensors=\"pt\", max_length=1024, truncation=True).to(device)\n\noutputs = model.generate(**inputs, max_length=300, min_length=80 ,num_beams=4 ,early_stopping=True  ,length_penalty=1.0, no_repeat_ngram_size=3)\nsummary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\nprint(\"summary:\", summary)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T05:42:16.758260Z","iopub.execute_input":"2025-06-02T05:42:16.758510Z","iopub.status.idle":"2025-06-02T05:42:22.545002Z","shell.execute_reply.started":"2025-06-02T05:42:16.758494Z","shell.execute_reply":"2025-06-02T05:42:22.544224Z"}},"outputs":[{"name":"stdout","text":"summary: Indian TV News +1 India Today +1 Election Outcomes BJP: 48 seats AAP: 22 seats Congress: 0 seats India TV News +3 India Today +3 Wikipedia +3 @mathrubhumi +5 The Times of India +5 Wikipedia +5 Business Standard Despite these setbacks, some AAP leaders managed to retain their seats: Atishi: Won from the Kalkaji constituency.Indead TV News: +1 Wikipedia +1 Leadership Changes Following the BJP's victory, Rekha Gupta was appointed as the Chief Minister of Delhi.Manish Sisodia: The former Deputy Chief Minister was defeated in the Jangpura constituency, became the first woman to hold this position in the city.In a landmark political shift, the Bharatiya Janata Party (BJP) has reclaimed power in the Delhi Legislative Assembly after a 27-year hiatus.\n","output_type":"stream"}],"execution_count":48}]}